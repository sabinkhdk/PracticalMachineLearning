---
title: "Practical Machine Learning Course project"
author: "Sabin Khadka"
date: "October 19, 2015"
output: html_document
---

##Introduction
In this project we use machine learning appraoch to classify activities according to the data collected from acceleromters of the belt, forearm, arm and dumbell of six male participants. The participants are asked to lift barbell in 5 different ways (1 correctly and 4 incorrectly). Class A: exactly according to the specification; class B: throwing the elbows to the front; Class C: lifting the dumbbell only halfway; Class D: lowering the dumbbell only halfway; Class E: throwing the hips to the front. More detailed explanation of the experiment and dataset are provided in Vellosso, E. et al. 2013. Refer to http://groupware.les.inf.puc-rio.br/har for more details. Here, in the current analysis we'll be using random forest tree and caret library functions to classify the activities. 

The training and testing datasets are downloaded from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv & https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv respectively.


```{r chunk1, echo=TRUE}
# Load caret and randomForest libraries in R
wd <- getwd() # working directory
library("caret")
library("randomForest")
# Set seed for reproducibility
set.seed(12345)
#If running for the first time create Project folder
dir.create("Project", showWarnings=FALSE)
cat("source URL for training and testing data")
# URL for training and testing datasets
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists("./Project/pml-training.csv")) {
        download.file(trainURL, destfile = "./Project/pml-training.csv", method = "curl")  
}
if (!file.exists("./Project/pml-testing.csv")) {
        download.file(testURL, destfile = "./Project/pml-testing.csv", method = "curl") 
}
trn_df <- read.csv("./Project/pml-training.csv", header =T, na.strings=c("NA",""))
tst_df <- read.csv("./Project/pml-testing.csv", header =T, na.strings=c("NA",""))
```

##Data exploration

First we'll check the proportion of missing data. We'll only consider the predictors containing 75% or more non-missing values. We'll remove all other predictors so as to maximize the number of observations.

```{r chunk2}
na_count <-data.frame(sapply(trn_df, function(y) sum(length(which(is.na(y))))))
na_prop <- na_count/dim(trn_df)[1]
trn_df1 <- trn_df[,!(na_prop>0.75)] # Remove columns with less than 75% of the valid data in training set
tst_df1 <- tst_df[,!(na_prop>0.75)] # Remove columns with less than 75% of the valid data in training set
```

Checking if new cleaned training dataset has NA values. Does training dataset contains NA's? `r any(is.na(trn_df1))`

Checking if new cleaned testing dataset has NA values. Does training dataset contains NA's? `r any(is.na(tst_df1))`

The remaining predictors are:

```{r}
colnames(trn_df1)
```

We'll remove the remove column that cannot be used as predictors (columns 1:7). Also, we'll check if any of the predictors are uninformative using near zero variance in caret. We'll remove any uniformative predictors that are constant (near zero variance) across the sample. 

```{r}
trn_df2 <- trn_df1[,c(8:dim(trn_df1)[2])]
tst_df2 <- tst_df1[,c(8:dim(tst_df1)[2])]
nZroVar <- nearZeroVar(trn_df2, saveMetrics = T) # Check for near zero variance predictors
trn_df2 <- trn_df2[,nZroVar$nzv==FALSE]
tst_df2 <- tst_df2[,nZroVar$nzv==FALSE]
```

List of final predictors:

```{r}
colnames(trn_df2[-length(trn_df2)])
```

Does training data have any predictors with near zero variance (TRUE=same; FALSE=losing some predictors)? `r unique((colnames(trn_df2)==colnames(trn_df1)[8:length(trn_df1)])) `

Next, we'll randomly split the training dataset set into train/test dataset into 60/40 prorportion. For this purpose we'll use createDataPartition function form caret. 

```{r}
inTrain <- createDataPartition(trn_df2$classe, p = 0.6, list =F, times =1)
trn_train <- trn_df2[inTrain,]
trn_test  <-trn_df2[-inTrain,]
```

Number of observations in training dataset: `r dim(trn_train)[1]`

Number of observations in testing dataset: `r dim(trn_test)[1]`

Building model for classification. We'll use random forest technique.

```{r}
# Random Forest takes very very long to run. Saved the model so as to no need to run next time. 
if(!file.exists("./Project/RForestModel1.Rdata")) {
        model1 <- train(classe ~ ., data = trn_train, method = "rf")
        save(model1, "./Project/RForestModel1.Rdata")
} else {
        load("./Project/RForestModel1.Rdata")
}
# Print the model
print(model1$finalModel)
```

For cross-validation we'll use the 40% of the splitted dataset from training set. The confusion matrix shows the expected and predicted classe of the cross-validation dataset, Accuracy and overall statistis of the model.


```{r}
predict_tst <- predict(model1, newdata = trn_test) 
ConfMat <- confusionMatrix(predict_tst, trn_test$classe)
# Print Confusion matrix
ConfMat
```

The out of sample error is `1-ConfMat[3]$overall[1]`. We can conclude that the model did performed well to classify different activities.

Predict and create test data submission files.

```{r}
predict_testSet <- predict(model1, newdata = tst_df2) 
pml_write_files = function(x) {
        n=length(x)
        for(i in 1:n){
                filename = paste0("problem_id_",i,".txt")
                write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
        }
}
setwd(paste0(wd,"/Project"))
pml_write_files(predict_testSet)
setwd(wd)
```
Reference. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.